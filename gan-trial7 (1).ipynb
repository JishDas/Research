{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# define varaibles\n\nnum_samples = 1096\n# taken from Feng Xue & P.R. Kumar et. al\nnearest_neighbours = 6\nnum_nodes = 256","metadata":{"execution":{"iopub.status.busy":"2022-12-17T13:16:46.586979Z","iopub.execute_input":"2022-12-17T13:16:46.587393Z","iopub.status.idle":"2022-12-17T13:16:46.640836Z","shell.execute_reply.started":"2022-12-17T13:16:46.587312Z","shell.execute_reply":"2022-12-17T13:16:46.639895Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import random\nimport time\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport numpy as np\nfrom torch import rand","metadata":{"execution":{"iopub.status.busy":"2022-12-17T13:16:46.659389Z","iopub.execute_input":"2022-12-17T13:16:46.659986Z","iopub.status.idle":"2022-12-17T13:16:50.253475Z","shell.execute_reply.started":"2022-12-17T13:16:46.659946Z","shell.execute_reply":"2022-12-17T13:16:50.252497Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# funtion to compute the distance between two points\ndef distance(x1,y1,x2,y2):\n    return np.sqrt((x2-x1)**2+(y2-y1)**2)","metadata":{"execution":{"iopub.status.busy":"2022-12-17T13:16:50.255704Z","iopub.execute_input":"2022-12-17T13:16:50.256357Z","iopub.status.idle":"2022-12-17T13:16:50.261303Z","shell.execute_reply.started":"2022-12-17T13:16:50.256314Z","shell.execute_reply":"2022-12-17T13:16:50.260307Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from queue import PriorityQueue\n\n# function to find the shortest distance between two points\ndef dijkstra(n,graph,start_vertex,weight):\n    D = [float('inf') for v in range(n)]\n    D[start_vertex] = 0\n    visited=[]\n\n    pq = PriorityQueue()\n    pq.put((0, start_vertex))\n\n    while not pq.empty():\n        (dist, current_vertex) = pq.get()\n        visited.append(current_vertex)\n\n        for neighbor in range(n):\n            if weight[current_vertex][neighbor] != -1:\n                distance = weight[current_vertex][neighbor]\n                if neighbor not in visited:\n                    old_cost = D[neighbor]\n                    new_cost = D[current_vertex] + distance\n                    if new_cost < old_cost:\n                        pq.put((new_cost, neighbor))\n                        D[neighbor] = new_cost\n    return D","metadata":{"execution":{"iopub.status.busy":"2022-12-17T13:16:50.262786Z","iopub.execute_input":"2022-12-17T13:16:50.263473Z","iopub.status.idle":"2022-12-17T13:16:50.274246Z","shell.execute_reply.started":"2022-12-17T13:16:50.263436Z","shell.execute_reply":"2022-12-17T13:16:50.273341Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def dataset_function(num_nodes,num_samples):\n    # create an adjacency matrix\n    adjacency_matrix = []\n    adjacency_matrix = np.array(adjacency_matrix)\n    \n    # create a distance matrix\n    distancematrix_final = []\n    distancematrix_final = np.array(distancematrix_final)\n    \n    Max = [[1e-7] for i in range(num_samples)]\n\n    for h in range(num_samples):\n\n        # randomly allocating the node coordinates\n        node_cordinates=rand(num_nodes,2)\n        node_cordinates = node_cordinates.numpy()\n\n        # creating a null matrix to work on\n        distance_matrix=np.zeros((num_nodes,num_nodes))\n\n        for i in range(num_nodes):\n            for j in range(i+1,num_nodes):\n                # computing te distance between the nodes\n                distance_matrix[i][j]= distance_matrix[j][i] = distance(node_cordinates[i][0],node_cordinates[i][1],node_cordinates[j][0],node_cordinates[j][1])\n        distancematrix_final = np.append(distancematrix_final, distance_matrix)\n        \n        # creating the adjacency matrix\n        t1=time.time()\n        G = nx.watts_strogatz_graph(n = num_nodes, k = 6, p=random.random())\n        t2=time.time()\n        spl=[]\n\n        for i in range(num_nodes):\n            D=dijkstra(num_nodes,G,i,distance_matrix)\n            spl.append(D)\n                    \n        aplSum=0.\n        for i in range(num_nodes):\n            aplSum+=np.sum(spl[i])\n        apl=aplSum/(num_samples*(num_nodes-1))\n        acc=nx.average_clustering(G)\n        G = nx.to_numpy_array(G)\n        if(t2-t1>0):\n            v=acc/(apl*(t2-t1))\n            if(v>=Max[h]):\n                adjacency_matrix = np.append(adjacency_matrix, G)\n    distancematrix_final = np.array(distancematrix_final)\n    distancematrix_final = distancematrix_final.reshape((num_samples,num_nodes,num_nodes))\n    adjacency_matrix = adjacency_matrix.reshape((num_samples,num_nodes,num_nodes))                   \n    return distancematrix_final, adjacency_matrix","metadata":{"execution":{"iopub.status.busy":"2022-12-17T13:16:50.277524Z","iopub.execute_input":"2022-12-17T13:16:50.277942Z","iopub.status.idle":"2022-12-17T13:16:50.290887Z","shell.execute_reply.started":"2022-12-17T13:16:50.277904Z","shell.execute_reply":"2022-12-17T13:16:50.289999Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":" dataset = dataset_function(num_nodes,num_samples)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = np.expand_dims(dataset,axis = -1)\ntestSrc, testTar = dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# example of pix2pix gan\nfrom numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model\nfrom keras.models import Input\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Concatenate\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import LeakyReLU\nfrom matplotlib import pyplot","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the discriminator model\ndef define_discriminator(image_shape):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02)\n\t# source image input\n\tin_src_image = Input(shape=image_shape)\n\t# target image input\n\tin_target_image = Input(shape=image_shape)\n\t# concatenate images channel-wise\n\tmerged = Concatenate()([in_src_image, in_target_image])\n\t# C64\n\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C128\n\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C256\n\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# C512\n\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# second last output layer\n\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n\td = BatchNormalization()(d)\n\td = LeakyReLU(alpha=0.2)(d)\n\t# patch output\n\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n\tpatch_out = Activation('sigmoid')(d)\n\t# define model\n\tmodel = Model([in_src_image, in_target_image], patch_out)\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n\treturn model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define an encoder block\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02)\n\t# add downsampling layer\n\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n\t# conditionally add batch normalization\n\tif batchnorm:\n\t\tg = BatchNormalization()(g, training=True)\n\t# leaky relu activation\n\tg = LeakyReLU(alpha=0.2)(g)\n\treturn g\n\n# define a decoder block\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02)\n\t# add upsampling layer\n\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n\t# add batch normalization\n\tg = BatchNormalization()(g, training=True)\n\t# conditionally add dropout\n\tif dropout:\n\t\tg = Dropout(0.5)(g, training=True)\n\t# merge with skip connection\n\tg = Concatenate()([g, skip_in])\n\t# relu activation\n\tg = Activation('relu')(g)\n\treturn g\n\n# define the standalone generator model\ndef define_generator(image_shape):\n\t# weight initialization\n\tinit = RandomNormal(stddev=0.02)\n\t# image input\n\tin_image = Input(shape=image_shape)\n\t# encoder model\n\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n\te2 = define_encoder_block(e1, 128)\n\te3 = define_encoder_block(e2, 256)\n\te4 = define_encoder_block(e3, 512)\n\te5 = define_encoder_block(e4, 512)\n\te6 = define_encoder_block(e5, 512)\n\te7 = define_encoder_block(e6, 512)\n\t# bottleneck, no batch norm and relu\n\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n\tb = Activation('relu')(b)\n\t# decoder model\n\td1 = decoder_block(b, e7, 512)\n\td2 = decoder_block(d1, e6, 512)\n\td3 = decoder_block(d2, e5, 512)\n\td4 = decoder_block(d3, e4, 512, dropout=False)\n\td5 = decoder_block(d4, e3, 256, dropout=False)\n\td6 = decoder_block(d5, e2, 128, dropout=False)\n\td7 = decoder_block(d6, e1, 64, dropout=False)\n\t# output\n\tg = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n\tout_image = Activation('tanh')(g)\n\t# define model\n\tmodel = Model(in_image, out_image)\n\treturn model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the combined generator and discriminator model, for updating the generator\ndef define_gan(g_model, d_model, image_shape):\n\t# make weights in the discriminator not trainable\n\tfor layer in d_model.layers:\n\t\tif not isinstance(layer, BatchNormalization):\n\t\t\tlayer.trainable = False\n\t# define the source image\n\tin_src = Input(shape=image_shape)\n\t# connect the source image to the generator input\n\tgen_out = g_model(in_src)\n\t# connect the source input and generator output to the discriminator input\n\tdis_out = d_model([in_src, gen_out])\n\t# src image as input, generated image and classification output\n\tmodel = Model(in_src, [dis_out, gen_out])\n\t# compile model\n\topt = Adam(lr=0.0002, beta_1=0.5)\n\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n\treturn model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load and prepare training images\ndef load_real_samples(filename):\n\tX1, X2 = testSrc, testTar\n\t# scale from [0,255] to [-1,1]\n\tX1 = (X1 - 127.5) / 127.5\n\tX2 = (X2 - 127.5) / 127.5\n\treturn [X1, X2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select a batch of random samples, returns images and target\ndef generate_real_samples(dataset, n_samples, patch_shape):\n\t# unpack dataset\n\ttrainA, trainB = dataset\n\t# choose random instances\n\tix = randint(0, trainA.shape[0], n_samples)\n\t# retrieve selected images\n\tX1, X2 = trainA[ix], trainB[ix]\n\t# generate 'real' class labels (1)\n\ty = ones((n_samples, patch_shape, patch_shape, 1))\n\treturn [X1, X2], y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate a batch of images, returns images and targets\ndef generate_fake_samples(g_model, samples, patch_shape):\n\t# generate fake instance\n\tX = g_model.predict(samples)\n\t# create 'fake' class labels (0)\n\ty = zeros((len(X), patch_shape, patch_shape, 1))\n\treturn X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate samples and save as a plot and save the model\ndef summarize_performance(step, g_model, dataset, n_samples=3):\n\t# select a sample of input images\n\t[X_realA, X_realB], _ = generate_real_samples(dataset, n_samples, 1)\n\t# generate a batch of fake samples\n\tX_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n\t# scale all pixels from [-1,1] to [0,1]\n\tX_realA = (X_realA + 1) / 2.0\n\tX_realB = (X_realB + 1) / 2.0\n\tX_fakeB = (X_fakeB + 1) / 2.0\n\t# plot real source images\n\tfor i in range(n_samples):\n\t\tpyplot.subplot(3, n_samples, 1 + i)\n\t\tpyplot.axis('off')\n\t\tpyplot.imshow(X_realA[i])\n\t# plot generated target image\n\tfor i in range(n_samples):\n\t\tpyplot.subplot(3, n_samples, 1 + n_samples + i)\n\t\tpyplot.axis('off')\n\t\tpyplot.imshow(X_fakeB[i])\n\t# plot real target image\n\tfor i in range(n_samples):\n\t\tpyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n\t\tpyplot.axis('off')\n\t\tpyplot.imshow(X_realB[i])\n\t# save plot to file\n\tfilename1 = 'plot_%06d.png' % (step+1)\n\tpyplot.savefig(filename1)\n\tpyplot.close()\n\t# save the generator model\n\tfilename2 = 'model_%06d.h5' % (step+1)\n\tg_model.save(filename2)\n\tprint('>Saved: %s and %s' % (filename1, filename2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train pix2pix model\ndef train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1):\n\t# determine the output square shape of the discriminator\n\tn_patch = d_model.output_shape[1]\n\t# unpack dataset\n\ttrainA, trainB = dataset\n\t# calculate the number of batches per training epoch\n\tbat_per_epo = int(len(trainA) / n_batch)\n\t# calculate the number of training iterations\n\tn_steps = bat_per_epo * n_epochs\n\t# manually enumerate epochs\n\tfor i in range(n_steps):\n\t\t# select a batch of real samples\n\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n\t\t# generate a batch of fake samples\n\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n\t\t# update discriminator for real samples\n\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n\t\t# update discriminator for generated samples\n\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n\t\t# update the generator\n\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n\t\t# summarize performance\n\t\tprint('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n\t\t# summarize model performance\n\t\tif (i+1) % (bat_per_epo * 10) == 0:\n\t\t\tsummarize_performance(i, g_model, dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the models\nimage_shape = ([num_nodes, num_nodes, 1])\nd_model = define_discriminator(image_shape)\ng_model = define_generator(image_shape)\n# define the composite model\ngan_model = define_gan(g_model, d_model, image_shape)\n# train model\ntrain(d_model, g_model, gan_model, dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create validation dataset\ndataset_val = dataset_function(num_nodes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = load_model('model_109600.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ValSrc, ValTar = dataset_val\n# select random example\nix = randint(0, len(ValSrc), 1)\nsrc_image, tar_image = ValSrc[ix], ValTar[ix]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate image from source\ngen_image = model.predict(src_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot source, generated and target images\ndef plot_images(src_img, gen_img, tar_img):\n\timages = vstack((src_img, gen_img, tar_img))\n\t# scale from [-1,1] to [0,1]\n\timages = (images + 1) / 2.0\n\ttitles = ['Source', 'Generated', 'Expected']\n\t# plot images row by row\n\tfor i in range(len(images)):\n\t\t# define subplot\n\t\tpyplot.subplot(1, 3, 1 + i)\n\t\t# turn off axis\n\t\tpyplot.axis('off')\n\t\t# plot raw pixel data\n\t\tpyplot.imshow(images[i])\n\t\t# show title\n\t\tpyplot.title(titles[i])\n\tpyplot.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom numpy import load\nfrom numpy import vstack\nfrom matplotlib import pyplot\nfrom numpy.random import randint\n# plot all three images\nplot_images(src_image, gen_image, tar_image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}